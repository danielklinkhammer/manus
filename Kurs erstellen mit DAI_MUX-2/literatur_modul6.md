# Kommentiertes Literaturverzeichnis - Modul 6: Transparenz, Vertrauen und Ethik in der KI-Interaktion

## Grundlagenliteratur

### Bücher

1. **Pasquale, F. (2015). The Black Box Society: The Secret Algorithms That Control Money and Information. Harvard University Press.**  
   *Eine einflussreiche Analyse der Intransparenz algorithmischer Systeme und ihrer gesellschaftlichen Auswirkungen. Das Buch bietet eine kritische Perspektive auf die "Black Box"-Natur vieler KI-Systeme und argumentiert für mehr Transparenz und Rechenschaftspflicht.*

2. **O'Neil, C. (2016). Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Crown.**  
   *Eine kritische Analyse der sozialen Auswirkungen von Algorithmen und Big Data. Das Buch untersucht, wie mathematische Modelle Ungleichheit verstärken können und plädiert für ethischere Ansätze in der Entwicklung und Anwendung von KI.*

3. **Floridi, L. (2019). The Ethics of Information. Oxford University Press.**  
   *Ein grundlegendes Werk zur Informationsethik, das einen philosophischen Rahmen für das Verständnis ethischer Fragen im Zusammenhang mit Informationstechnologien, einschließlich KI, bietet.*

4. **Dignum, V. (2019). Responsible Artificial Intelligence: How to Develop and Use AI in a Responsible Way. Springer.**  
   *Dieses Buch bietet einen umfassenden Überblick über verantwortungsvolle KI und diskutiert ethische, rechtliche und gesellschaftliche Aspekte der KI-Entwicklung und -Nutzung.*

5. **Selbst, A. D., Boyd, D., Friedler, S. A., Venkatasubramanian, S., & Vertesi, J. (2019). Fairness and Abstraction in Sociotechnical Systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency (pp. 59-68). ACM.**  
   *Dieser einflussreiche Artikel untersucht die Herausforderungen bei der Gewährleistung von Fairness in soziotechnischen Systemen und bietet einen konzeptionellen Rahmen für das Verständnis dieser Herausforderungen.*

### Wissenschaftliche Artikel

1. **Amershi, S., Weld, D., Vorvoreanu, M., Fourney, A., Nushi, B., Collisson, P., ... & Horvitz, E. (2019). Guidelines for Human-AI Interaction. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (pp. 1-13). ACM.**  
   *Diese einflussreiche Arbeit aus der ACM Digital Library präsentiert 18 allgemeine Richtlinien für die Gestaltung von Mensch-KI-Interaktionen, mit besonderem Fokus auf Transparenz und Vertrauenswürdigkeit.*

2. **Ehsan, U., & Riedl, M. O. (2020). Human-Centered Explainable AI: Towards a Reflective Sociotechnical Approach. In International Conference on Human-Computer Interaction (pp. 449-466). Springer.**  
   *Dieser Artikel stellt einen menschenzentrierten Ansatz für erklärbare KI vor und betont die Bedeutung von Reflexivität und soziotechnischen Überlegungen bei der Gestaltung erklärbarer KI-Systeme.*

3. **Liao, Q. V., Gruen, D., & Miller, S. (2020). Questioning the AI: Informing Design Practices for Explainable AI User Experiences. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (pp. 1-15). ACM.**  
   *Diese Arbeit aus der ACM Digital Library untersucht, wie Nutzer Fragen an KI-Systeme stellen und welche Arten von Erklärungen sie erwarten. Die Ergebnisse bieten wertvolle Einblicke für das Design erklärbarer KI-Systeme.*

4. **Ehsan, U., Liao, Q. V., Muller, M., Riedl, M. O., & Weisz, J. D. (2021). Expanding Explainability: Towards Social Transparency in AI systems. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems (pp. 1-19). ACM.**  
   *Dieser Artikel aus der ACM Digital Library führt das Konzept der "sozialen Transparenz" in KI-Systemen ein und erweitert damit traditionelle Ansätze zur Erklärbarkeit von KI.*

5. **Shneiderman, B. (2020). Human-Centered Artificial Intelligence: Reliable, Safe & Trustworthy. International Journal of Human–Computer Interaction, 36(6), 495-504.**  
   *Dieser Artikel diskutiert die Prinzipien menschenzentrierter KI und bietet einen Rahmen für die Entwicklung zuverlässiger, sicherer und vertrauenswürdiger KI-Systeme.*

## Erklärbare KI (XAI)

### Bücher

1. **Miller, T. (2019). Explanation in Artificial Intelligence: Insights from the Social Sciences. Artificial Intelligence, 267, 1-38.**  
   *Ein grundlegender Übersichtsartikel, der Erkenntnisse aus den Sozialwissenschaften auf die Erklärbarkeit von KI anwendet und einen interdisziplinären Rahmen für das Verständnis von Erklärungen bietet.*

2. **Molnar, C. (2020). Interpretable Machine Learning. Lulu.com.**  
   *Ein umfassendes Werk zu interpretierbarem maschinellem Lernen, das verschiedene Methoden und Techniken zur Erklärung von ML-Modellen vorstellt und diskutiert.*

### Wissenschaftliche Artikel

1. **Ribeiro, M. T., Singh, S., & Guestrin, C. (2016). "Why Should I Trust You?": Explaining the Predictions of Any Classifier. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (pp. 1135-1144). ACM.**  
   *Dieser einflussreiche Artikel aus der ACM Digital Library stellt LIME vor, eine Technik zur Erklärung der Vorhersagen beliebiger Klassifikatoren, und diskutiert die Bedeutung von Erklärbarkeit für das Vertrauen in KI-Systeme.*

2. **Lundberg, S. M., & Lee, S. I. (2017). A Unified Approach to Interpreting Model Predictions. In Advances in Neural Information Processing Systems (pp. 4765-4774).**  
   *Dieser Artikel stellt SHAP (SHapley Additive exPlanations) vor, einen einheitlichen Ansatz zur Interpretation von Modellvorhersagen, der auf spieltheoretischen Konzepten basiert.*

3. **Wachter, S., Mittelstadt, B., & Russell, C. (2017). Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR. Harvard Journal of Law & Technology, 31(2), 841-887.**  
   *Dieser Artikel diskutiert kontrafaktische Erklärungen als Methode zur Erklärung automatisierter Entscheidungen im Kontext der DSGVO, ohne die "Black Box" zu öffnen.*

4. **Ehsan, U., Tambwekar, P., Chan, L., Harrison, B., & Riedl, M. O. (2019). Automated Rationale Generation: A Technique for Explainable AI and its Effects on Human Perceptions. In Proceedings of the 24th International Conference on Intelligent User Interfaces (pp. 263-274). ACM.**  
   *Dieser Artikel aus der ACM Digital Library stellt eine Technik zur automatisierten Begründungsgenerierung für erklärbare KI vor und untersucht deren Auswirkungen auf die menschliche Wahrnehmung.*

5. **Wang, D., Yang, Q., Abdul, A., & Lim, B. Y. (2019). Designing Theory-Driven User-Centric Explainable AI. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (pp. 1-15). ACM.**  
   *Diese Arbeit aus der ACM Digital Library stellt einen theoriegeleiteten, nutzerzentrierten Ansatz für erklärbare KI vor und bietet praktische Designrichtlinien.*

## Vertrauen und Transparenz in KI-Systemen

### Bücher

1. **Hoffman, R. R., Johnson, M., Bradshaw, J. M., & Underbrink, A. (2013). Trust in Automation. IEEE Intelligent Systems, 28(1), 84-88.**  
   *Ein grundlegender Artikel zum Vertrauen in Automatisierung, der verschiedene Faktoren diskutiert, die das Vertrauen in automatisierte Systeme beeinflussen.*

2. **Lee, J. D., & See, K. A. (2004). Trust in Automation: Designing for Appropriate Reliance. Human Factors, 46(1), 50-80.**  
   *Ein einflussreicher Artikel zum Design für angemessenes Vertrauen in Automatisierung, der verschiedene Faktoren diskutiert, die das Vertrauen in automatisierte Systeme beeinflussen.*

### Wissenschaftliche Artikel

1. **Kizilcec, R. F. (2016). How Much Information? Effects of Transparency on Trust in an Algorithmic Interface. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (pp. 2390-2395). ACM.**  
   *Dieser Artikel aus der ACM Digital Library untersucht die Auswirkungen von Transparenz auf das Vertrauen in algorithmische Schnittstellen und bietet Einblicke in die optimale Menge an Informationen für verschiedene Nutzergruppen.*

2. **Cheng, H. F., Wang, R., Zhang, Z., O'Connell, F., Gray, T., Harper, F. M., & Zhu, H. (2019). Explaining Decision-Making Algorithms through UI: Strategies to Help Non-Expert Stakeholders. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (pp. 1-12). ACM.**  
   *Dieser Artikel aus der ACM Digital Library untersucht Strategien zur Erklärung von Entscheidungsalgorithmen durch Benutzeroberflächen für nicht-technische Stakeholder.*

3. **Eiband, M., Schneider, H., Bilandzic, M., Fazekas-Con, J., Haug, M., & Hussmann, H. (2018). Bringing Transparency Design into Practice. In 23rd International Conference on Intelligent User Interfaces (pp. 211-223). ACM.**  
   *Diese Arbeit aus der ACM Digital Library stellt einen praktischen Ansatz für Transparenzdesign vor und bietet Einblicke in die Umsetzung von Transparenzprinzipien in der Praxis.*

4. **Rader, E., Cotter, K., & Cho, J. (2018). Explanations as Mechanisms for Supporting Algorithmic Transparency. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (pp. 1-13). ACM.**  
   *Dieser Artikel aus der ACM Digital Library untersucht Erklärungen als Mechanismen zur Unterstützung algorithmischer Transparenz und bietet Einblicke in die Wirksamkeit verschiedener Erklärungsarten.*

5. **Dodge, J., Liao, Q. V., Zhang, Y., Bellamy, R. K., & Dugan, C. (2019). Explaining Models: An Empirical Study of How Explanations Impact Fairness Judgment. In Proceedings of the 24th International Conference on Intelligent User Interfaces (pp. 275-285). ACM.**  
   *Diese Arbeit aus der ACM Digital Library untersucht empirisch, wie Erklärungen die Fairnessbeurteilung von KI-Modellen beeinflussen, und bietet Einblicke in die Gestaltung effektiver Erklärungen.*

## Ethik und Fairness in der KI

### Bücher

1. **Mittelstadt, B. D., Allo, P., Taddeo, M., Wachter, S., & Floridi, L. (2016). The Ethics of Algorithms: Mapping the Debate. Big Data & Society, 3(2), 2053951716679679.**  
   *Ein grundlegender Übersichtsartikel, der die ethische Debatte um Algorithmen kartiert und verschiedene ethische Herausforderungen und Perspektiven diskutiert.*

2. **Barocas, S., & Selbst, A. D. (2016). Big Data's Disparate Impact. California Law Review, 104, 671-732.**  
   *Ein einflussreicher Artikel, der die disparaten Auswirkungen von Big Data und maschinellem Lernen auf verschiedene soziale Gruppen untersucht und rechtliche und ethische Implikationen diskutiert.*

### Wissenschaftliche Artikel

1. **Holstein, K., Wortman Vaughan, J., Daumé III, H., Dudik, M., & Wallach, H. (2019). Improving Fairness in Machine Learning Systems: What Do Industry Practitioners Need?. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (pp. 1-16). ACM.**  
   *Diese Arbeit aus der ACM Digital Library untersucht die Bedürfnisse von Praktikern bei der Verbesserung der Fairness in maschinellen Lernsystemen und bietet Einblicke in praktische Herausforderungen und Lösungsansätze.*

2. **Friedman, B., & Hendry, D. G. (2019). Value Sensitive Design: Shaping Technology with Moral Imagination. MIT Press.**  
   *Ein grundlegendes Werk zum Value Sensitive Design, das einen methodischen Ansatz zur Integration ethischer Werte in den Technologiedesignprozess vorstellt.*

3. **Selbst, A. D., Boyd, D., Friedler, S. A., Venkatasubramanian, S., & Vertesi, J. (2019). Fairness and Abstraction in Sociotechnical Systems. In Proceedings of the Conference on Fairness, Accountability, and Transparency (pp. 59-68). ACM.**  
   *Dieser Artikel aus der ACM Digital Library untersucht die Herausforderungen bei der Gewährleistung von Fairness in soziotechnischen Systemen und identifiziert fünf "Fairness-Abstraktionsfallen".*

4. **Madaio, M. A., Stark, L., Wortman Vaughan, J., & Wallach, H. (2020). Co-Designing Checklists to Understand Organizational Challenges and Opportunities around Fairness in AI. In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems (pp. 1-14). ACM.**  
   *Diese Arbeit aus der ACM Digital Library stellt einen co-design-Ansatz für Checklisten vor, um organisatorische Herausforderungen und Chancen rund um Fairness in KI zu verstehen.*

5. **Wong, R. Y. (2021). Tactics of Soft Resistance in User Experience Professionals' Values Work. Proceedings of the ACM on Human-Computer Interaction, 5(CSCW1), 1-23.**  
   *Dieser Artikel aus der ACM Digital Library untersucht Taktiken des "weichen Widerstands" in der Wertearbeit von UX-Fachleuten und bietet Einblicke in die praktische Umsetzung ethischer Prinzipien in der Technologieentwicklung.*

## Praxisorientierte Ressourcen

1. **Google's People + AI Guidebook: https://pair.withgoogle.com/guidebook/**  
   *Eine umfassende Ressource mit praktischen Richtlinien und Best Practices für das Design menschenzentrierter KI-Produkte, mit besonderem Fokus auf Transparenz und Vertrauen.*

2. **Microsoft's Guidelines for Human-AI Interaction: https://www.microsoft.com/en-us/research/project/guidelines-for-human-ai-interaction/**  
   *Eine Sammlung von 18 Richtlinien für die Gestaltung von Mensch-KI-Interaktionen, basierend auf umfangreicher Forschung von Microsoft.*

3. **IBM's AI Ethics Board: https://www.ibm.com/artificial-intelligence/ethics**  
   *Eine Ressource zu IBMs Ansatz für KI-Ethik, einschließlich Prinzipien, Richtlinien und praktischer Tools für ethische KI-Entwicklung.*

4. **The Institute for Ethical AI & Machine Learning: https://ethical.institute/**  
   *Eine Organisation, die sich der Förderung ethischer KI-Praktiken widmet und verschiedene Ressourcen, Richtlinien und Tools für Praktiker anbietet.*

5. **AI Fairness 360: https://aif360.mybluemix.net/**  
   *Eine Open-Source-Bibliothek zur Erkennung und Minderung von Bias in maschinellen Lernmodellen, entwickelt von IBM Research.*
