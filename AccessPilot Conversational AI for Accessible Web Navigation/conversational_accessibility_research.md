# Forschungslage HCI/UX & Conversational Accessibility

## Überblick zu Conversational Interfaces für Barrierefreiheit

Conversational Interfaces (CUIs) bieten ein erhebliches Potenzial für die Verbesserung der Barrierefreiheit im Web, insbesondere für blinde und sehbehinderte Nutzer. Die Forschung in diesem Bereich hat in den letzten Jahren deutlich zugenommen, wobei verschiedene Ansätze und Technologien untersucht werden.

## Grundlegende Konzepte und Vorteile

### Natürliche Interaktion statt Befehlserinnerung

Ein zentraler Vorteil von Conversational Interfaces ist, dass Nutzer nicht mehr spezifische Befehle oder Navigationsmethoden erlernen und erinnern müssen. Wie in einem Artikel des Knight Lab (2016) hervorgehoben wird:

> "Eine Schnittstelle, die nicht davon abhängt, dass Benutzer bestimmte Befehle oder Interaktionsmethoden abrufen können, ist von Natur aus zugänglich: Jede Person nutzt das System auf ihre eigene Weise, sodass jeder Anwendungsfall berücksichtigt wird. Benutzer müssen ihre Absichten nicht mehr in Aktionen übersetzen. Jetzt ist die Absicht die Aktion."

Diese Eigenschaft macht CUIs besonders wertvoll für blinde Nutzer, die sonst mit komplexen Tastenkombinationen und linearen Navigationsstrukturen in Screenreadern konfrontiert sind.

### Kontextbewusstsein und personalisierte Interaktion

Moderne Conversational Interfaces, insbesondere solche, die auf KI und maschinellem Lernen basieren, können Kontext verstehen und personalisierte Antworten liefern. Dies ermöglicht eine intuitivere und effizientere Interaktion als traditionelle Screenreader-Ansätze.

Mariansky (zitiert in Knight Lab, 2016) beschreibt die ideale konversationelle Schnittstelle als "eine Suchmaschine, die nur ein Ergebnis liefert" - das perfekte Ergebnis für den Nutzer in seinem spezifischen Kontext und seiner aktuellen Situation.

## Aktuelle Forschungsansätze

### Conversational Interfaces für blinde Wissensarbeiter

Eine Fallstudie von Dent und Ramea (2020) untersuchte die Entwicklung einer konversationellen Benutzeroberfläche für Multifunktionsdrucker, die speziell auf die Bedürfnisse blinder Wissensarbeiter zugeschnitten ist. Die Studie betont, wie moderne Touchscreen-Interfaces in Bürogeräten größere Hindernisse für blinde Nutzer schaffen und zu einer Umgebung der Abhängigkeit am Arbeitsplatz beitragen. Die Forscher arbeiteten mit einer Gruppe blinder und sehbehinderter Personen zusammen, um die Herausforderungen zu verstehen und eine aufgabenbasierte, kollaborative Interaktion zwischen Menschen und intelligenten Agenten zu entwickeln.

### LLM-basierte einheitliche Computerinteraktion

Eine innovative Studie von Kodandaram et al. (2024) präsentiert "Savant", eine neuartige assistive Technologie, die durch Large Language Models (LLMs) angetrieben wird. Savant ermöglicht es blinden Screenreader-Nutzern, über natürliche Sprache einheitlich mit jeder Anwendungsschnittstelle zu interagieren. Das System kann eine Reihe von mühsamen Screenreader-Aktionen auf den Steuerelementen der Anwendung automatisieren, wenn es durch einen natürlichsprachlichen Befehl des Benutzers aufgefordert wird. Diese Befehle können flexibel sein, da der Benutzer nicht strikt die genauen Namen der Steuerelemente im Befehl angeben muss.

Eine Benutzerstudie mit 11 blinden Teilnehmern zeigte signifikante Verbesserungen in der Interaktionseffizienz und Benutzerfreundlichkeit im Vergleich zu herkömmlichen Praktiken.

### Zugängliche konversationelle Schnittstellen für Bildungseinrichtungen

Iñiguez-Carrillo et al. (2018) untersuchten die Entwicklung einer benutzerfreundlichen und zugänglichen konversationellen Schnittstelle für ein mexikanisches Universitätssystem. Die Studie betont, dass konversationelle Schnittstellen Barrierefreiheit für Benutzer mit geringen technischen Fähigkeiten und die Integration von Benutzern mit Behinderungen (visuell oder motorisch) ermöglichen. Die Forscher identifizierten Benutzerherausforderungen für Personen mit visuellen und motorischen Behinderungen und entwickelten eine Schnittstelle, die intuitiver und effizienter ist.

## Identifizierte Forschungslücken

Aus der Literaturrecherche lassen sich mehrere Forschungslücken identifizieren, die für das AccessPilot-Projekt relevant sind:

1. **Semantische Analyse von Webinhalten**: Während viele Studien sich auf die Interaktion mit Anwendungen konzentrieren, gibt es weniger Forschung zur semantischen Analyse und Strukturierung von Webinhalten für blinde Nutzer.

2. **Aufgabenorientierte Navigation**: Es fehlt an Forschung zu aufgabenorientierten Navigationsansätzen, die über die lineare Struktur traditioneller Screenreader hinausgehen.

3. **Kontextbewusstes Filtern von Informationen**: Die intelligente Filterung und Priorisierung von Webinhalten basierend auf dem Nutzerkontext und der aktuellen Aufgabe ist ein unterentwickelter Bereich.

4. **Multimodale Interaktion**: Die Kombination von Spracheingabe, natürlicher Sprachverarbeitung und taktiler Rückmeldung für ein umfassendes Zugänglichkeitserlebnis ist noch nicht ausreichend erforscht.

5. **Evaluierungsmethoden**: Es fehlen standardisierte Methoden zur Bewertung der Effektivität konversationeller Schnittstellen für blinde Nutzer im Vergleich zu traditionellen Screenreadern.

## Relevanz für AccessPilot

Die identifizierten Forschungslücken bieten erhebliches Innovationspotenzial für AccessPilot:

1. Die semantische Analyse von Webinhalten, ein Kernaspekt von AccessPilot, adressiert direkt eine der identifizierten Forschungslücken.

2. Der konversationelle UI-Ansatz von AccessPilot ermöglicht eine natürlichere und intuitivere Interaktion als traditionelle Screenreader, was durch aktuelle Forschungsergebnisse unterstützt wird.

3. Die Fähigkeit, Webinhalte intelligent zu strukturieren und zu filtern, adressiert die Probleme der linearen Navigation und fehlenden Kontextbewusstseins in herkömmlichen Screenreadern.

4. Die Zusammenarbeit mit der Schweizerischen Bibliothek für Blinde, Seh- und Lesebehinderte (SBS) bietet eine wertvolle Möglichkeit, die Effektivität des AccessPilot-Ansatzes zu evaluieren und zur Forschung in diesem Bereich beizutragen.

## Quellen

- Dent, K., & Ramea, K. (2020). Conversational User Interfaces for Blind Knowledge Workers: A Case Study. arXiv:2006.07519.
- Kodandaram, S. R., Uckun, U., Bi, X., Ramakrishnan, I. V., & Ashok, V. (2024). Enabling Uniform Computer Interaction Experience for Blind Users through Large Language Models. Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility.
- Iñiguez-Carrillo, A. L., García-Ruiz, M. A., Gaytán-Lugo, L. S., & Maciel-Arellano, R. (2018). Development of a Usable and Accessible Conversational Interface for a Mexican University System. HCI-XB 2018.
- Knight Lab (2016). How conversational interfaces make the internet more accessible for everyone. Northwestern University.
- Bridging Accessibility Gaps for the Visually Impaired in a Chatbot Web Chat (2024). ACM Digital Library.
