# C-XAI: A conceptual framework for designing XAI tools that support trust calibration

## Bibliografische Informationen
- **Autoren**: Mohammad Naiseh, Auste Simkute, Baraa Zieni, Nan Jiang, Raian Ali
- **Veröffentlicht**: März 2024
- **Journal**: Journal of Responsible Technology, Volume 17
- **DOI**: https://doi.org/10.1016/j.jrt.2024.100076
- **Typ**: Forschungsartikel
- **Zugang**: Open Access

## Zusammenfassung
Dieser Artikel stellt ein konzeptionelles Framework namens "Calibrated-XAI" (C-XAI) vor, das speziell für die Gestaltung von XAI-Interfaces (eXplainable AI) entwickelt wurde, die eine Vertrauenskalibrierung in der Mensch-KI-Zusammenarbeit unterstützen. Die Autoren argumentieren, dass mit der zunehmenden Integration von KI in kritischen Bereichen wie Gesundheitswesen und Justiz die Kalibrierung des Vertrauens zwischen Mensch und KI entscheidend ist, um Fehler durch übermäßiges oder unzureichendes Vertrauen zu vermeiden. Das C-XAI-Framework ist eine partizipative Designmethode, die sowohl technische als auch menschliche Faktoren bei der Gestaltung von XAI-Interfaces berücksichtigt. Es bietet Templates, Anleitungen und bezieht verschiedene Stakeholder in den Designprozess ein, um Designern zu helfen, Benutzeroberflächen zu entwickeln, die eine angemessene Vertrauenskalibrierung fördern.

## Relevanz für "Interface of One"
Diese Arbeit ist für das Projekt "Interface of One" besonders relevant, da sie sich mit einem zentralen Aspekt agentenbasierter Interfaces befasst: dem Vertrauen zwischen Mensch und KI-System. Das vorgestellte C-XAI-Framework bietet einen methodischen Ansatz zur Gestaltung von Interfaces, die Transparenz, Erklärbarkeit und angemessenes Vertrauen fördern - alles wesentliche Elemente für die Vision eines intelligenten, personalisierten Systems, das als Vermittler zwischen Nutzer und digitaler Welt fungiert. Die Arbeit zeigt, wie wichtig es ist, sowohl technische Aspekte der KI-Erklärbarkeit als auch menschliche Faktoren wie kognitive Verzerrungen und Verhaltensmuster zu berücksichtigen.

## Schlüsselkonzepte
1. **Vertrauenskalibrierung**: Das angemessene Niveau des Vertrauens in KI-Empfehlungen, weder übermäßiges noch unzureichendes Vertrauen.
2. **eXplainable AI (XAI)**: Methoden und Techniken, die die Logik und Entscheidungsfindung von KI-Systemen transparent und verständlich machen.
3. **Partizipatives Design**: Ein Ansatz, der verschiedene Stakeholder in den Designprozess einbezieht, um bessere Ergebnisse zu erzielen.
4. **Human-Centered XAI**: Ein Designansatz, der den Menschen in den Mittelpunkt der Entwicklung erklärbarer KI-Systeme stellt.
5. **Mensch-KI-Zusammenarbeit**: Die Kombination menschlicher und künstlicher Intelligenz zur Verbesserung der Entscheidungsqualität.

## Verbindung zu anderen Themenbereichen
- **Conversational und Agentic UX**: Die Arbeit befasst sich direkt mit der Gestaltung von Interfaces für die Mensch-KI-Interaktion und adressiert Vertrauen, Transparenz und Erklärbarkeit.
- **Multimodale, adaptive Interfaces**: Das Framework könnte auf verschiedene Modalitäten der Erklärung angewendet werden, um kontextadaptive Erklärungen zu liefern.
- **Zero UI / Invisible UX**: Die Herausforderung der Vertrauenskalibrierung wird noch komplexer, wenn Interfaces weniger sichtbar oder ambient werden.

## Methodischer Ansatz
Die Autoren verwenden einen partizipativen Designansatz, der verschiedene Stakeholder in den Prozess einbezieht. Das C-XAI-Framework wurde in einer zweistufigen Evaluationsstudie getestet, um seine Wirksamkeit bei der Unterstützung von Designern bei der Entwicklung von Benutzeroberflächen mit Fokus auf Vertrauenskalibrierung zu demonstrieren.

## Implikationen für das Design
1. **Berücksichtigung technischer und menschlicher Faktoren**: Designer müssen sowohl die technischen Eigenschaften von XAI-Methoden als auch menschliche Faktoren wie kognitive Verzerrungen berücksichtigen.
2. **Partizipativer Ansatz**: Die Einbeziehung verschiedener Stakeholder in den Designprozess kann zu besseren Ergebnissen führen.
3. **Fokus auf Vertrauenskalibrierung**: Statt einfach nur Erklärungen zu liefern, sollten Interfaces darauf abzielen, ein angemessenes Vertrauensniveau zu fördern.
4. **Systematische Anleitung**: Designer benötigen systematische Anleitungen und Templates, um effektive XAI-Interfaces zu gestalten.
